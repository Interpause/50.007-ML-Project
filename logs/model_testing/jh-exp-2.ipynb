{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2304c4be",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": [
        "### REMOVE LATER ###\n",
        "# Go up one directory since notebook inside task3/ folder.\n",
        "import os\n",
        "\n",
        "try:\n",
        "    if UP_DIR:\n",
        "        print(\"skipping\")\n",
        "except NameError:\n",
        "    os.chdir(\"..\")\n",
        "    UP_DIR = True"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8ad56939",
      "metadata": {
        "trusted": false
      },
      "source": [
        "# JH's Task 3 Experiment 2\n",
        "(NOTE: keep this H1 header block or add it later to denote the boundaries between notebooks when we combined later)\n",
        "\n",
        "Attempting Hyperparameter Sweep using Optuna."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "be8e8fa9",
      "metadata": {
        "trusted": false
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8c26973c",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import optuna\n",
        "from copy import deepcopy\n",
        "from task3.exp2 import Hparams, tfidf_to_np, train, inference\n",
        "from dataclasses import asdict\n",
        "import matplotlib.pyplot as plt\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import f1_score\n",
        "import json\n",
        "import os\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "31d84100",
      "metadata": {
        "trusted": false
      },
      "source": [
        "## Hyperparameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "b15db208",
      "metadata": {
        "trusted": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Experiment: optuna_exp_20250810_231224\n",
            "Logs will be saved to: ./logs/optuna_exp_20250810_231224\n"
          ]
        }
      ],
      "source": [
        "TRAIN_CSV = \"./data/train.csv\"\n",
        "TRAIN_TFIDF_CSV = \"./data/train_tfidf_features_custom.csv\"\n",
        "TEST_CSV = \"./data/test.csv\"\n",
        "TEST_TFIDF_CSV = \"./data/test_tfidf_features_custom.csv\"\n",
        "HP = Hparams()\n",
        "\n",
        "HP.val_split = 0.4\n",
        "\n",
        "# Setup logging\n",
        "EXPERIMENT_NAME = f\"optuna_exp_{datetime.now().strftime('%Y%m%d_%H%M%S')}\"\n",
        "LOG_DIR = f\"./logs/{EXPERIMENT_NAME}\"\n",
        "os.makedirs(LOG_DIR, exist_ok=True)\n",
        "\n",
        "TRIAL_LOG_FILE = os.path.join(LOG_DIR, \"trial_results.jsonl\")\n",
        "\n",
        "print(f\"Experiment: {EXPERIMENT_NAME}\")\n",
        "print(f\"Logs will be saved to: {LOG_DIR}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e36c357",
      "metadata": {
        "trusted": false
      },
      "source": [
        "## Data Engineering\n",
        "Instead of using the tfidf features given in the comp, we can engineer our own tfidf features with better filtering logic, or using something other than tfidf altogether to arrive at vector representations, or perhaps even use a strategy that use non-vector representations."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "361d387f",
      "metadata": {
        "trusted": false
      },
      "source": [
        "### Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "d5e58864",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": [
        "# train_df = pd.read_csv(TRAIN_CSV, index_col=\"id\")\n",
        "train_tfidf_df = pd.read_csv(TRAIN_TFIDF_CSV, index_col=\"id\")\n",
        "# test_df = pd.read_csv(TEST_CSV, index_col=\"id\")\n",
        "test_tfidf_df = pd.read_csv(TEST_TFIDF_CSV, index_col=\"id\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "d8bd2b4a",
      "metadata": {
        "trusted": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset splits:\n",
            "  train: 10310\n",
            "  val:   6874\n",
            "  test:  4296\n"
          ]
        }
      ],
      "source": [
        "test_X, test_y = tfidf_to_np(test_tfidf_df)\n",
        "train_X, train_y = tfidf_to_np(train_tfidf_df)\n",
        "train_X, val_X, train_y, val_y = train_test_split(\n",
        "    train_X,\n",
        "    train_y,\n",
        "    test_size=HP.val_split,\n",
        "    random_state=HP.seed,\n",
        "    stratify=train_y,\n",
        ")\n",
        "\n",
        "print(\"Dataset splits:\")\n",
        "print(\"  train:\", len(train_X))\n",
        "print(\"  val:  \", len(val_X))\n",
        "print(\"  test: \", len(test_X))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ffbaf306",
      "metadata": {
        "trusted": false
      },
      "source": [
        "## Optuna Hyperparameter Optimization\n",
        "Setting up hyperparameter search using Optuna to find optimal parameters for our XGBoost + PCA pipeline."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "d03b3545",
      "metadata": {},
      "outputs": [],
      "source": [
        "def log_trial_result(trial_number, params, results, hp, timestamp):\n",
        "    \"\"\"Log trial results to JSONL.\"\"\"\n",
        "    \n",
        "    # Prepare data for logging\n",
        "    log_entry = {\n",
        "        \"trial_number\": trial_number,\n",
        "        \"timestamp\": timestamp,\n",
        "        \"val_f1\": results.get(\"val_f1\"),\n",
        "        \"train_f1\": results.get(\"train_f1\"),\n",
        "        \"f1_discrepancy\": results.get(\"f1_discrepancy\"),\n",
        "        \"val_err\": results.get(\"val_err\"),\n",
        "        \"train_err\": results.get(\"train_err\"),\n",
        "        \"err_discrepancy\": results.get(\"err_discrepancy\"),\n",
        "        \"hyperparameters\": {\n",
        "            # Optuna suggested parameters\n",
        "            **params,\n",
        "            # All hyperparameters from HP object\n",
        "            \"val_split\": hp.val_split,\n",
        "            \"seed\": hp.seed,\n",
        "            \"num_rounds\": hp.num_rounds,\n",
        "            \"early_stopping_rounds\": hp.early_stopping_rounds,\n",
        "            \"dim_reduction_method\": hp.dim_reduction_method,\n",
        "            \"xgb_num_parallel_tree\": hp.xgb_num_parallel_tree,\n",
        "        }\n",
        "    }\n",
        "    \n",
        "    # Log to JSONL file (one JSON object per line)\n",
        "    with open(TRIAL_LOG_FILE, \"a\") as f:\n",
        "        f.write(json.dumps(log_entry) + \"\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "115b05f3",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": [
        "def objective(trial: optuna.Trial):\n",
        "    \"\"\"Objective function for Optuna optimization.\"\"\"\n",
        "    \n",
        "    trial_start_time = datetime.now()\n",
        "\n",
        "    # Create a copy of base hyperparameters\n",
        "    hp = deepcopy(HP)\n",
        "    hp.num_rounds = 100000\n",
        "    # hp.num_rounds = 1\n",
        "    hp.early_stopping_rounds = 500\n",
        "\n",
        "    # Go back to use gradient boosted trees\n",
        "    hp.xgb_num_parallel_tree = 1\n",
        "    # hp.xgb_num_parallel_tree = trial.suggest_int(\n",
        "    #     \"xgb_num_parallel_tree\", 10, 200, step=10\n",
        "    # )\n",
        "\n",
        "    \"\"\" From previous experiment:\n",
        "    Parameters:\n",
        "        xgb_max_depth: 12\n",
        "        xgb_learning_rate: 0.0020001869132760825\n",
        "        xgb_subsample: 0.45260442438907245\n",
        "        xgb_colsample_bynode: 0.3421942471972495\n",
        "        xgb_min_child_weight: 10.60087486325813\n",
        "        xgb_min_split_loss: 2.056364343369845\n",
        "        xgb_lambda: 5.950284635850967\n",
        "        xgb_alpha: 10.285767928640595\n",
        "    \"\"\"\n",
        "\n",
        "    # Tuning to reduce overfitting\n",
        "    hp.dim_reduction_method = \"svd\"\n",
        "    # Use fewer components to reduce overfitting to noise\n",
        "    hp.dim_n_components = trial.suggest_int(\"dim_n_components\", 100, 1000, step=100)\n",
        "    # Shallow trees to prevent overfitting (also train faster)\n",
        "    # notably deep trees still perform better despite the overfit tendency.\n",
        "    hp.xgb_max_depth = trial.suggest_int(\"xgb_max_depth\", 3, 10)\n",
        "    # Lower learning rates for more conservative updates\n",
        "    hp.xgb_learning_rate = trial.suggest_float(\n",
        "        \"xgb_learning_rate\", 0.0001, 0.01, log=True\n",
        "    )\n",
        "    # Aggressive subsampling to prevent overfitting\n",
        "    hp.xgb_subsample = trial.suggest_float(\"xgb_subsample\", 0.1, 0.8)\n",
        "    # Aggressive feature subsampling for regularization\n",
        "    hp.xgb_colsample_bynode = trial.suggest_float(\"xgb_colsample_bynode\", 0.1, 0.7)\n",
        "    # Higher min_child_weight to prevent overfitting to small groups\n",
        "    hp.xgb_min_child_weight = trial.suggest_float(\"xgb_min_child_weight\", 5.0, 20.0)\n",
        "    # Higher min_split_loss to make splits more conservative\n",
        "    hp.xgb_min_split_loss = trial.suggest_float(\"xgb_min_split_loss\", 1.0, 5.0)\n",
        "    # Strong L2 regularization\n",
        "    hp.xgb_lambda = trial.suggest_float(\"xgb_lambda\", 5.0, 20.0)\n",
        "    # Strong L1 regularization for feature selection\n",
        "    hp.xgb_alpha = trial.suggest_float(\"xgb_alpha\", 5.0, 20.0)\n",
        "\n",
        "    try:\n",
        "        # Train model with suggested hyperparameters\n",
        "        results = train(\n",
        "            hp, train_X=train_X, train_y=train_y, val_X=val_X, val_y=val_y, quiet=True\n",
        "        )\n",
        "\n",
        "        # Store results\n",
        "        # trial.set_user_attr(\"model_xgb\", results[\"model_xgb\"])\n",
        "        # trial.set_user_attr(\"model_dim\", results[\"model_dim\"])\n",
        "        # lets not oom please\n",
        "        trial.set_user_attr(\"model_xgb\", None)\n",
        "        trial.set_user_attr(\"model_dim\", None)\n",
        "        trial.set_user_attr(\"f1_discrepancy\", results[\"f1_discrepancy\"])\n",
        "        trial.set_user_attr(\"hyperparameters\", hp)\n",
        "\n",
        "        # Log trial results to file\n",
        "        log_trial_result(\n",
        "            trial_number=trial.number,\n",
        "            params=trial.params,\n",
        "            results=results,\n",
        "            hp=hp,\n",
        "            timestamp=trial_start_time.isoformat()\n",
        "        )\n",
        "\n",
        "        if trial.number % 10 == 0:\n",
        "            print(\n",
        "                f\"{datetime.now()} #{trial.number}: f1: {results['val_f1']:.4f}, discrepancy: {results['f1_discrepancy']:.4f}\"\n",
        "            )\n",
        "\n",
        "        return results[\"val_f1\"]\n",
        "\n",
        "    except Exception as e:\n",
        "        error_msg = f\"Trial failed with error: {e}\"\n",
        "        print(error_msg)\n",
        "        \n",
        "        # Log failed trial\n",
        "        failed_results = {\n",
        "            \"val_f1\": 0.0,\n",
        "            \"train_f1\": 0.0,\n",
        "            \"f1_discrepancy\": 0.0,\n",
        "            \"val_err\": 1.0,\n",
        "            \"train_err\": 1.0,\n",
        "            \"err_discrepancy\": 0.0,\n",
        "            \"error\": str(e)\n",
        "        }\n",
        "        \n",
        "        log_trial_result(\n",
        "            trial_number=trial.number,\n",
        "            params=trial.params,\n",
        "            results=failed_results,\n",
        "            hp=hp,\n",
        "            timestamp=trial_start_time.isoformat()\n",
        "        )\n",
        "        \n",
        "        # Return low value for failed trials\n",
        "        return 0.0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "28fc1c36",
      "metadata": {
        "trusted": false
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "45cb77cd11f34f3da33b5b19cf0d2fd8",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "   0%|          | 00:00/1:00:00"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2025-08-10 21:39:28.390885 #0: f1: 0.6868, discrepancy: 0.2696\n",
            "2025-08-10 21:43:43.231811 #10: f1: 0.6516, discrepancy: 0.1421\n",
            "2025-08-10 21:43:43.231811 #10: f1: 0.6516, discrepancy: 0.1421\n",
            "2025-08-10 21:47:05.969546 #20: f1: 0.6864, discrepancy: 0.2257\n",
            "2025-08-10 21:47:05.969546 #20: f1: 0.6864, discrepancy: 0.2257\n",
            "2025-08-10 21:51:43.534611 #30: f1: 0.6762, discrepancy: 0.1213\n",
            "2025-08-10 21:51:43.534611 #30: f1: 0.6762, discrepancy: 0.1213\n",
            "2025-08-10 21:55:24.880671 #40: f1: 0.6593, discrepancy: 0.0807\n",
            "2025-08-10 21:55:24.880671 #40: f1: 0.6593, discrepancy: 0.0807\n",
            "2025-08-10 21:58:22.273638 #50: f1: 0.6762, discrepancy: 0.1599\n",
            "2025-08-10 21:58:22.273638 #50: f1: 0.6762, discrepancy: 0.1599\n",
            "2025-08-10 22:01:30.071653 #60: f1: 0.6914, discrepancy: 0.2722\n",
            "2025-08-10 22:01:30.071653 #60: f1: 0.6914, discrepancy: 0.2722\n",
            "2025-08-10 22:04:24.617275 #70: f1: 0.6458, discrepancy: 0.0656\n",
            "2025-08-10 22:04:24.617275 #70: f1: 0.6458, discrepancy: 0.0656\n",
            "2025-08-10 22:08:04.178475 #80: f1: 0.6720, discrepancy: 0.1667\n",
            "2025-08-10 22:08:04.178475 #80: f1: 0.6720, discrepancy: 0.1667\n",
            "2025-08-10 22:12:00.660804 #90: f1: 0.6863, discrepancy: 0.2785\n",
            "2025-08-10 22:12:00.660804 #90: f1: 0.6863, discrepancy: 0.2785\n",
            "2025-08-10 22:16:06.198142 #100: f1: 0.6909, discrepancy: 0.2228\n",
            "2025-08-10 22:16:06.198142 #100: f1: 0.6909, discrepancy: 0.2228\n",
            "[W 2025-08-10 22:16:30,011] Trial 102 failed with parameters: {'dim_n_components': 500, 'xgb_max_depth': 5, 'xgb_learning_rate': 0.008016932202894561, 'xgb_subsample': 0.667944797999947, 'xgb_colsample_bynode': 0.29919362771389263, 'xgb_min_child_weight': 14.885554932921, 'xgb_min_split_loss': 1.3277103576077496, 'xgb_lambda': 8.53280726718046, 'xgb_alpha': 10.26960234306209} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_128807/4145487332.py\", line 56, in objective\n",
            "    results = train(\n",
            "              ^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/task3/exp2.py\", line 191, in train\n",
            "    model_xgb = xgb.train(\n",
            "                ^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/xgboost/training.py\", line 184, in train\n",
            "    if cb_container.after_iteration(bst, i, dtrain, evals):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/xgboost/callback.py\", line 264, in after_iteration\n",
            "    score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 2366, in eval_set\n",
            "    feval_ret = feval(\n",
            "                ^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/task3/exp2.py\", line 126, in macro_f1_eval\n",
            "    f1_macro = f1_score(y_true, y_pred_binary, average=\"macro\")\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 218, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1465, in f1_score\n",
            "    return fbeta_score(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 191, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1658, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 191, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1971, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1737, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 98, in _check_targets\n",
            "    type_true = type_of_target(y_true, input_name=\"y_true\")\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/utils/multiclass.py\", line 348, in type_of_target\n",
            "    warnings.simplefilter(\"error\", VisibleDeprecationWarning)\n",
            "  File \"/home/jh/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/warnings.py\", line 168, in simplefilter\n",
            "    def simplefilter(action, category=Warning, lineno=0, append=False):\n",
            "    \n",
            "KeyboardInterrupt\n",
            "[W 2025-08-10 22:16:30,016] Trial 102 failed with value None.\n",
            "[W 2025-08-10 22:16:30,011] Trial 102 failed with parameters: {'dim_n_components': 500, 'xgb_max_depth': 5, 'xgb_learning_rate': 0.008016932202894561, 'xgb_subsample': 0.667944797999947, 'xgb_colsample_bynode': 0.29919362771389263, 'xgb_min_child_weight': 14.885554932921, 'xgb_min_split_loss': 1.3277103576077496, 'xgb_lambda': 8.53280726718046, 'xgb_alpha': 10.26960234306209} because of the following error: KeyboardInterrupt().\n",
            "Traceback (most recent call last):\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py\", line 201, in _run_trial\n",
            "    value_or_values = func(trial)\n",
            "                      ^^^^^^^^^^^\n",
            "  File \"/tmp/ipykernel_128807/4145487332.py\", line 56, in objective\n",
            "    results = train(\n",
            "              ^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/task3/exp2.py\", line 191, in train\n",
            "    model_xgb = xgb.train(\n",
            "                ^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 729, in inner_f\n",
            "    return func(**kwargs)\n",
            "           ^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/xgboost/training.py\", line 184, in train\n",
            "    if cb_container.after_iteration(bst, i, dtrain, evals):\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/xgboost/callback.py\", line 264, in after_iteration\n",
            "    score: str = model.eval_set(evals, epoch, self.metric, self._output_margin)\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/xgboost/core.py\", line 2366, in eval_set\n",
            "    feval_ret = feval(\n",
            "                ^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/task3/exp2.py\", line 126, in macro_f1_eval\n",
            "    f1_macro = f1_score(y_true, y_pred_binary, average=\"macro\")\n",
            "               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 218, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1465, in f1_score\n",
            "    return fbeta_score(\n",
            "           ^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 191, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1658, in fbeta_score\n",
            "    _, _, f, _ = precision_recall_fscore_support(\n",
            "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py\", line 191, in wrapper\n",
            "    return func(*args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1971, in precision_recall_fscore_support\n",
            "    labels = _check_set_wise_labels(y_true, y_pred, average, labels, pos_label)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 1737, in _check_set_wise_labels\n",
            "    y_type, y_true, y_pred = _check_targets(y_true, y_pred)\n",
            "                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py\", line 98, in _check_targets\n",
            "    type_true = type_of_target(y_true, input_name=\"y_true\")\n",
            "                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/home/jh/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/utils/multiclass.py\", line 348, in type_of_target\n",
            "    warnings.simplefilter(\"error\", VisibleDeprecationWarning)\n",
            "  File \"/home/jh/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/warnings.py\", line 168, in simplefilter\n",
            "    def simplefilter(action, category=Warning, lineno=0, append=False):\n",
            "    \n",
            "KeyboardInterrupt\n",
            "[W 2025-08-10 22:16:30,016] Trial 102 failed with value None.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;66;03m# optuna.logging.set_verbosity(optuna.logging.INFO)\u001b[39;00m\n\u001b[32m      4\u001b[39m study = optuna.create_study(\n\u001b[32m      5\u001b[39m     direction=\u001b[33m\"\u001b[39m\u001b[33mmaximize\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     \u001b[38;5;66;03m# Use TPE sampler for reproducibility\u001b[39;00m\n\u001b[32m      7\u001b[39m     sampler=optuna.samplers.TPESampler(seed=HP.seed),\n\u001b[32m      8\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mstudy\u001b[49m\u001b[43m.\u001b[49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobjective\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m60\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mBest validation macro F1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstudy.best_value\u001b[38;5;132;01m:\u001b[39;00m\u001b[33m.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mBest hyperparameters:\u001b[39m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/optuna/study/study.py:489\u001b[39m, in \u001b[36mStudy.optimize\u001b[39m\u001b[34m(self, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m    387\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34moptimize\u001b[39m(\n\u001b[32m    388\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    389\u001b[39m     func: ObjectiveFuncType,\n\u001b[32m   (...)\u001b[39m\u001b[32m    396\u001b[39m     show_progress_bar: \u001b[38;5;28mbool\u001b[39m = \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    397\u001b[39m ) -> \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    398\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Optimize an objective function.\u001b[39;00m\n\u001b[32m    399\u001b[39m \n\u001b[32m    400\u001b[39m \u001b[33;03m    Optimization is done by choosing a suitable set of hyperparameter values from a given\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    487\u001b[39m \u001b[33;03m            If nested invocation of this method occurs.\u001b[39;00m\n\u001b[32m    488\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m489\u001b[39m     \u001b[43m_optimize\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    490\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    491\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    492\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    493\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    494\u001b[39m \u001b[43m        \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mtuple\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mIterable\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    496\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    497\u001b[39m \u001b[43m        \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    498\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshow_progress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    499\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:64\u001b[39m, in \u001b[36m_optimize\u001b[39m\u001b[34m(study, func, n_trials, timeout, n_jobs, catch, callbacks, gc_after_trial, show_progress_bar)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     63\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m n_jobs == \u001b[32m1\u001b[39m:\n\u001b[32m---> \u001b[39m\u001b[32m64\u001b[39m         \u001b[43m_optimize_sequential\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     65\u001b[39m \u001b[43m            \u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     66\u001b[39m \u001b[43m            \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     67\u001b[39m \u001b[43m            \u001b[49m\u001b[43mn_trials\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     68\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m            \u001b[49m\u001b[43mgc_after_trial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m            \u001b[49m\u001b[43mreseed_sampler_rng\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtime_start\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m            \u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprogress_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     76\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     77\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m n_jobs == -\u001b[32m1\u001b[39m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:161\u001b[39m, in \u001b[36m_optimize_sequential\u001b[39m\u001b[34m(study, func, n_trials, timeout, catch, callbacks, gc_after_trial, reseed_sampler_rng, time_start, progress_bar)\u001b[39m\n\u001b[32m    158\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     frozen_trial = \u001b[43m_run_trial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudy\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    163\u001b[39m     \u001b[38;5;66;03m# The following line mitigates memory problems that can be occurred in some\u001b[39;00m\n\u001b[32m    164\u001b[39m     \u001b[38;5;66;03m# environments (e.g., services that use computing containers such as GitHub Actions).\u001b[39;00m\n\u001b[32m    165\u001b[39m     \u001b[38;5;66;03m# Please refer to the following PR for further details:\u001b[39;00m\n\u001b[32m    166\u001b[39m     \u001b[38;5;66;03m# https://github.com/optuna/optuna/pull/325.\u001b[39;00m\n\u001b[32m    167\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m gc_after_trial:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:253\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    246\u001b[39m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mShould not reach.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    248\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    249\u001b[39m     frozen_trial.state == TrialState.FAIL\n\u001b[32m    250\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m func_err \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    251\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(func_err, catch)\n\u001b[32m    252\u001b[39m ):\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m func_err\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m frozen_trial\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/optuna/study/_optimize.py:201\u001b[39m, in \u001b[36m_run_trial\u001b[39m\u001b[34m(study, func, catch)\u001b[39m\n\u001b[32m    199\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m get_heartbeat_thread(trial._trial_id, study._storage):\n\u001b[32m    200\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m201\u001b[39m         value_or_values = \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    202\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m exceptions.TrialPruned \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    203\u001b[39m         \u001b[38;5;66;03m# TODO(mamu): Handle multi-objective cases.\u001b[39;00m\n\u001b[32m    204\u001b[39m         state = TrialState.PRUNED\n",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 56\u001b[39m, in \u001b[36mobjective\u001b[39m\u001b[34m(trial)\u001b[39m\n\u001b[32m     52\u001b[39m hp.xgb_alpha = trial.suggest_float(\u001b[33m\"\u001b[39m\u001b[33mxgb_alpha\u001b[39m\u001b[33m\"\u001b[39m, \u001b[32m5.0\u001b[39m, \u001b[32m20.0\u001b[39m)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     55\u001b[39m     \u001b[38;5;66;03m# Train model with suggested hyperparameters\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     results = \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     57\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_X\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     58\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# Store results\u001b[39;00m\n\u001b[32m     61\u001b[39m     \u001b[38;5;66;03m# trial.set_user_attr(\"model_xgb\", results[\"model_xgb\"])\u001b[39;00m\n\u001b[32m     62\u001b[39m     \u001b[38;5;66;03m# trial.set_user_attr(\"model_dim\", results[\"model_dim\"])\u001b[39;00m\n\u001b[32m     63\u001b[39m     \u001b[38;5;66;03m# lets not oom please\u001b[39;00m\n\u001b[32m     64\u001b[39m     trial.set_user_attr(\u001b[33m\"\u001b[39m\u001b[33mmodel_xgb\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/task3/exp2.py:191\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(HP, train_X, train_y, val_X, val_y, quiet)\u001b[39m\n\u001b[32m    188\u001b[39m eval_list = [(dtrain, \u001b[33m\"\u001b[39m\u001b[33mtrain\u001b[39m\u001b[33m\"\u001b[39m), (dval, \u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m)]\n\u001b[32m    190\u001b[39m results = {}\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m model_xgb = \u001b[43mxgb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    192\u001b[39m \u001b[43m    \u001b[49m\u001b[43mxgb_params\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    193\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    194\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_boost_round\u001b[49m\u001b[43m=\u001b[49m\u001b[43mHP\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnum_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    195\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    196\u001b[39m \u001b[43m    \u001b[49m\u001b[43mevals_result\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresults\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    197\u001b[39m \u001b[43m    \u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m=\u001b[49m\u001b[43mHP\u001b[49m\u001b[43m.\u001b[49m\u001b[43mearly_stopping_rounds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcustom_metric\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmacro_f1_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    200\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# verbose_eval=200,\u001b[39;49;00m\n\u001b[32m    201\u001b[39m \u001b[43m    \u001b[49m\u001b[43mverbose_eval\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mquiet\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[32;43m50\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    202\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    204\u001b[39m best_iter = model_xgb.best_iteration\n\u001b[32m    205\u001b[39m val_f1 = results[\u001b[33m\"\u001b[39m\u001b[33mval\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mmacro_f1\u001b[39m\u001b[33m\"\u001b[39m][best_iter]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/xgboost/core.py:729\u001b[39m, in \u001b[36mrequire_keyword_args.<locals>.throw_if.<locals>.inner_f\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    727\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k, arg \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(sig.parameters, args):\n\u001b[32m    728\u001b[39m     kwargs[k] = arg\n\u001b[32m--> \u001b[39m\u001b[32m729\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/xgboost/training.py:184\u001b[39m, in \u001b[36mtrain\u001b[39m\u001b[34m(params, dtrain, num_boost_round, evals, obj, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, custom_metric)\u001b[39m\n\u001b[32m    182\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    183\u001b[39m     bst.update(dtrain, iteration=i, fobj=obj)\n\u001b[32m--> \u001b[39m\u001b[32m184\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mcb_container\u001b[49m\u001b[43m.\u001b[49m\u001b[43mafter_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevals\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    185\u001b[39m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    187\u001b[39m bst = cb_container.after_training(bst)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/xgboost/callback.py:264\u001b[39m, in \u001b[36mCallbackContainer.after_iteration\u001b[39m\u001b[34m(self, model, epoch, dtrain, evals)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, name \u001b[38;5;129;01min\u001b[39;00m evals:\n\u001b[32m    263\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m name.find(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m) == -\u001b[32m1\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mDataset name should not contain `-`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m264\u001b[39m score: \u001b[38;5;28mstr\u001b[39m = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43meval_set\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevals\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmetric\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_output_margin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    265\u001b[39m metric_score = _parse_eval_str(score)\n\u001b[32m    266\u001b[39m \u001b[38;5;28mself\u001b[39m._update_history(metric_score, epoch)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/xgboost/core.py:2366\u001b[39m, in \u001b[36mBooster.eval_set\u001b[39m\u001b[34m(self, evals, iteration, feval, output_margin)\u001b[39m\n\u001b[32m   2364\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m feval \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   2365\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m dmat, evname \u001b[38;5;129;01min\u001b[39;00m evals:\n\u001b[32m-> \u001b[39m\u001b[32m2366\u001b[39m         feval_ret = \u001b[43mfeval\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2367\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_margin\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2368\u001b[39m \u001b[43m            \u001b[49m\u001b[43mdmat\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2369\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2370\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(feval_ret, \u001b[38;5;28mlist\u001b[39m):\n\u001b[32m   2371\u001b[39m             \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m feval_ret:\n\u001b[32m   2372\u001b[39m                 \u001b[38;5;66;03m# pylint: disable=consider-using-f-string\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/task3/exp2.py:126\u001b[39m, in \u001b[36mmacro_f1_eval\u001b[39m\u001b[34m(y_pred, dtrain)\u001b[39m\n\u001b[32m    123\u001b[39m y_pred_binary = (y_pred > \u001b[32m0.5\u001b[39m).astype(\u001b[38;5;28mint\u001b[39m)\n\u001b[32m    125\u001b[39m \u001b[38;5;66;03m# Calculate macro F1 score (average of F1 scores for both classes)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m f1_macro = \u001b[43mf1_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred_binary\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmacro\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[38;5;66;03m# Return tuple: (metric_name, metric_value)\u001b[39;00m\n\u001b[32m    129\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mmacro_f1\u001b[39m\u001b[33m\"\u001b[39m, f1_macro\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:218\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    213\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[32m    214\u001b[39m         skip_parameter_validation=(\n\u001b[32m    215\u001b[39m             prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[32m    216\u001b[39m         )\n\u001b[32m    217\u001b[39m     ):\n\u001b[32m--> \u001b[39m\u001b[32m218\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m InvalidParameterError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    220\u001b[39m     \u001b[38;5;66;03m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m# message to avoid confusion.\u001b[39;00m\n\u001b[32m    224\u001b[39m     msg = re.sub(\n\u001b[32m    225\u001b[39m         \u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[33m\\\u001b[39m\u001b[33mw+ must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    226\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mparameter of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc.\u001b[34m__qualname__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m must be\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    227\u001b[39m         \u001b[38;5;28mstr\u001b[39m(e),\n\u001b[32m    228\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1465\u001b[39m, in \u001b[36mf1_score\u001b[39m\u001b[34m(y_true, y_pred, labels, pos_label, average, sample_weight, zero_division)\u001b[39m\n\u001b[32m   1285\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   1286\u001b[39m     {\n\u001b[32m   1287\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msparse matrix\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1312\u001b[39m     zero_division=\u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1313\u001b[39m ):\n\u001b[32m   1314\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the F1 score, also known as balanced F-score or F-measure.\u001b[39;00m\n\u001b[32m   1315\u001b[39m \n\u001b[32m   1316\u001b[39m \u001b[33;03m    The F1 score can be interpreted as a harmonic mean of the precision and\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1463\u001b[39m \u001b[33;03m    array([0.66666667, 1.        , 0.66666667])\u001b[39;00m\n\u001b[32m   1464\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1465\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfbeta_score\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1466\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1467\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1468\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1469\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1470\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1471\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1472\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1473\u001b[39m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1474\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1658\u001b[39m, in \u001b[36mfbeta_score\u001b[39m\u001b[34m(y_true, y_pred, beta, labels, pos_label, average, sample_weight, zero_division)\u001b[39m\n\u001b[32m   1477\u001b[39m \u001b[38;5;129m@validate_params\u001b[39m(\n\u001b[32m   1478\u001b[39m     {\n\u001b[32m   1479\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33my_true\u001b[39m\u001b[33m\"\u001b[39m: [\u001b[33m\"\u001b[39m\u001b[33marray-like\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msparse matrix\u001b[39m\u001b[33m\"\u001b[39m],\n\u001b[32m   (...)\u001b[39m\u001b[32m   1506\u001b[39m     zero_division=\u001b[33m\"\u001b[39m\u001b[33mwarn\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   1507\u001b[39m ):\n\u001b[32m   1508\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Compute the F-beta score.\u001b[39;00m\n\u001b[32m   1509\u001b[39m \n\u001b[32m   1510\u001b[39m \u001b[33;03m    The F-beta score is the weighted harmonic mean of precision and recall,\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1655\u001b[39m \u001b[33;03m    0.128\u001b[39;00m\n\u001b[32m   1656\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1658\u001b[39m     _, _, f, _ = \u001b[43mprecision_recall_fscore_support\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1659\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1660\u001b[39m \u001b[43m        \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1661\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbeta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1662\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1663\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1664\u001b[39m \u001b[43m        \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m=\u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1665\u001b[39m \u001b[43m        \u001b[49m\u001b[43mwarn_for\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mf-score\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1666\u001b[39m \u001b[43m        \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m=\u001b[49m\u001b[43msample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1667\u001b[39m \u001b[43m        \u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m=\u001b[49m\u001b[43mzero_division\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1668\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1669\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m f\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/utils/_param_validation.py:191\u001b[39m, in \u001b[36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    189\u001b[39m global_skip_validation = get_config()[\u001b[33m\"\u001b[39m\u001b[33mskip_parameter_validation\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_skip_validation:\n\u001b[32m--> \u001b[39m\u001b[32m191\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    193\u001b[39m func_sig = signature(func)\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Map *args/**kwargs to the function signature\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1971\u001b[39m, in \u001b[36mprecision_recall_fscore_support\u001b[39m\u001b[34m(y_true, y_pred, beta, labels, pos_label, average, warn_for, sample_weight, zero_division)\u001b[39m\n\u001b[32m   1802\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Compute precision, recall, F-measure and support for each class.\u001b[39;00m\n\u001b[32m   1803\u001b[39m \n\u001b[32m   1804\u001b[39m \u001b[33;03mThe precision is the ratio ``tp / (tp + fp)`` where ``tp`` is the number of\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1968\u001b[39m \u001b[33;03m array([2, 2, 2]))\u001b[39;00m\n\u001b[32m   1969\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1970\u001b[39m _check_zero_division(zero_division)\n\u001b[32m-> \u001b[39m\u001b[32m1971\u001b[39m labels = \u001b[43m_check_set_wise_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maverage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos_label\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1973\u001b[39m \u001b[38;5;66;03m# Calculate tp_sum, pred_sum, true_sum ###\u001b[39;00m\n\u001b[32m   1974\u001b[39m samplewise = average == \u001b[33m\"\u001b[39m\u001b[33msamples\u001b[39m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1737\u001b[39m, in \u001b[36m_check_set_wise_labels\u001b[39m\u001b[34m(y_true, y_pred, average, labels, pos_label)\u001b[39m\n\u001b[32m   1734\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33maverage has to be one of \u001b[39m\u001b[33m\"\u001b[39m + \u001b[38;5;28mstr\u001b[39m(average_options))\n\u001b[32m   1736\u001b[39m y_true, y_pred = attach_unique(y_true, y_pred)\n\u001b[32m-> \u001b[39m\u001b[32m1737\u001b[39m y_type, y_true, y_pred = \u001b[43m_check_targets\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1738\u001b[39m \u001b[38;5;66;03m# Convert to Python primitive type to avoid NumPy type / Python str\u001b[39;00m\n\u001b[32m   1739\u001b[39m \u001b[38;5;66;03m# comparison. See https://github.com/numpy/numpy/issues/6784\u001b[39;00m\n\u001b[32m   1740\u001b[39m present_labels = _tolist(unique_labels(y_true, y_pred))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/metrics/_classification.py:98\u001b[39m, in \u001b[36m_check_targets\u001b[39m\u001b[34m(y_true, y_pred)\u001b[39m\n\u001b[32m     96\u001b[39m xp, _ = get_namespace(y_true, y_pred)\n\u001b[32m     97\u001b[39m check_consistent_length(y_true, y_pred)\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m type_true = \u001b[43mtype_of_target\u001b[49m\u001b[43m(\u001b[49m\u001b[43my_true\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_name\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43my_true\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m type_pred = type_of_target(y_pred, input_name=\u001b[33m\"\u001b[39m\u001b[33my_pred\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    101\u001b[39m y_type = {type_true, type_pred}\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/code/repos-comp-school/50.007-ML-Project/.venv/lib/python3.12/site-packages/sklearn/utils/multiclass.py:348\u001b[39m, in \u001b[36mtype_of_target\u001b[39m\u001b[34m(y, input_name, raise_unknown)\u001b[39m\n\u001b[32m    338\u001b[39m check_y_kwargs = \u001b[38;5;28mdict\u001b[39m(\n\u001b[32m    339\u001b[39m     accept_sparse=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    340\u001b[39m     allow_nd=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    344\u001b[39m     ensure_min_features=\u001b[32m0\u001b[39m,\n\u001b[32m    345\u001b[39m )\n\u001b[32m    347\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m warnings.catch_warnings():\n\u001b[32m--> \u001b[39m\u001b[32m348\u001b[39m     \u001b[43mwarnings\u001b[49m\u001b[43m.\u001b[49m\u001b[43msimplefilter\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43merror\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mVisibleDeprecationWarning\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    349\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m issparse(y):\n\u001b[32m    350\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/uv/python/cpython-3.12.11-linux-x86_64-gnu/lib/python3.12/warnings.py:168\u001b[39m, in \u001b[36msimplefilter\u001b[39m\u001b[34m(action, category, lineno, append)\u001b[39m\n\u001b[32m    164\u001b[39m         module = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    166\u001b[39m     _add_filter(action, message, category, module, lineno, append=append)\n\u001b[32m--> \u001b[39m\u001b[32m168\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msimplefilter\u001b[39m(action, category=\u001b[38;5;167;01mWarning\u001b[39;00m, lineno=\u001b[32m0\u001b[39m, append=\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[32m    169\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Insert a simple entry into the list of warnings filters (at the front).\u001b[39;00m\n\u001b[32m    170\u001b[39m \n\u001b[32m    171\u001b[39m \u001b[33;03m    A simple filter matches all modules and messages.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    176\u001b[39m \u001b[33;03m    'append' -- if true, append to the list of filters\u001b[39;00m\n\u001b[32m    177\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m action \u001b[38;5;129;01min\u001b[39;00m (\u001b[33m\"\u001b[39m\u001b[33merror\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mignore\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33malways\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mdefault\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mmodule\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    179\u001b[39m                       \u001b[33m\"\u001b[39m\u001b[33monce\u001b[39m\u001b[33m\"\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33minvalid action: \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m % (action,)\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
        "# optuna.logging.set_verbosity(optuna.logging.INFO)\n",
        "\n",
        "study = optuna.create_study(\n",
        "    direction=\"maximize\",\n",
        "    # Use TPE sampler for reproducibility\n",
        "    sampler=optuna.samplers.TPESampler(seed=HP.seed),\n",
        ")\n",
        "\n",
        "study.optimize(objective, timeout=60 * 60 * 1, show_progress_bar=True)\n",
        "\n",
        "print(f\"Best validation macro F1: {study.best_value:.4f}\")\n",
        "print(\"Best hyperparameters:\")\n",
        "for key, value in study.best_params.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "06a05d72",
      "metadata": {
        "trusted": false
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'study' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      5\u001b[39m fig, (ax1, ax2) = plt.subplots(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m12\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Optimization history\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m trial_numbers = [trial.number \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m \u001b[43mstudy\u001b[49m.trials]\n\u001b[32m      9\u001b[39m trial_values = [trial.value \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m study.trials \u001b[38;5;28;01mif\u001b[39;00m trial.value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[32m     10\u001b[39m trial_nums_valid = [trial.number \u001b[38;5;28;01mfor\u001b[39;00m trial \u001b[38;5;129;01min\u001b[39;00m study.trials \u001b[38;5;28;01mif\u001b[39;00m trial.value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m]\n",
            "\u001b[31mNameError\u001b[39m: name 'study' is not defined"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot optimization history\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Optimization history\n",
        "trial_numbers = [trial.number for trial in study.trials]\n",
        "trial_values = [trial.value for trial in study.trials if trial.value is not None]\n",
        "trial_nums_valid = [trial.number for trial in study.trials if trial.value is not None]\n",
        "\n",
        "ax1.plot(trial_nums_valid, trial_values, \"b-\", alpha=0.7)\n",
        "ax1.axhline(\n",
        "    y=max(trial_values),  # Best is now maximum F1\n",
        "    color=\"r\",\n",
        "    linestyle=\"--\",\n",
        "    alpha=0.7,\n",
        "    label=f\"Best: {max(trial_values):.4f}\",\n",
        ")\n",
        "ax1.set_xlabel(\"Trial Number\")\n",
        "ax1.set_ylabel(\"Validation Macro F1\")\n",
        "ax1.set_title(\"Optimization History\")\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# Parameter importance (if enough trials)\n",
        "importance = optuna.importance.get_param_importances(study)\n",
        "params = list(importance.keys())\n",
        "values = list(importance.values())\n",
        "\n",
        "ax2.barh(params, values)\n",
        "ax2.set_xlabel(\"Importance\")\n",
        "ax2.set_title(\"Hyperparameter Importance\")\n",
        "ax2.tick_params(axis=\"y\", labelsize=8)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Show best trial details\n",
        "print(\"Best Trial Details:\")\n",
        "print(f\"Trial number: {study.best_trial.number}\")\n",
        "print(f\"Validation macro F1: {study.best_trial.value:.4f}\")\n",
        "print(\"Parameters:\")\n",
        "for key, value in study.best_trial.params.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "b8f2cf19",
      "metadata": {},
      "outputs": [],
      "source": [
        "## Save Final Results and Create Experiment Summary\n",
        "# Save final optimization results\n",
        "final_results = {\n",
        "    \"experiment_name\": EXPERIMENT_NAME,\n",
        "    \"optimization_completed\": datetime.now().isoformat(),\n",
        "    \"total_trials\": len(study.trials),\n",
        "    \"best_trial_number\": study.best_trial.number,\n",
        "    \"best_val_f1\": study.best_value,\n",
        "    \"best_params\": study.best_params,\n",
        "    \"study_statistics\": {\n",
        "        \"n_complete\": len([t for t in study.trials if t.state == optuna.trial.TrialState.COMPLETE]),\n",
        "        \"n_failed\": len([t for t in study.trials if t.state == optuna.trial.TrialState.FAIL]),\n",
        "        \"n_pruned\": len([t for t in study.trials if t.state == optuna.trial.TrialState.PRUNED]),\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(os.path.join(LOG_DIR, \"final_results.json\"), \"w\") as f:\n",
        "    json.dump(final_results, f, indent=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "5479ad7b",
      "metadata": {
        "trusted": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Best model validation macro F1: 0.6951\n",
            "F1 Score Discrepancy: 0.2801\n",
            "Parameters:\n",
            "  dim_n_components: 600\n",
            "  xgb_max_depth: 5\n",
            "  xgb_learning_rate: 0.00556178353250608\n",
            "  xgb_subsample: 0.5635517015265841\n",
            "  xgb_colsample_bynode: 0.29465651555894085\n",
            "  xgb_min_child_weight: 15.509993186959967\n",
            "  xgb_min_split_loss: 1.457161565140586\n",
            "  xgb_lambda: 8.047558328691794\n",
            "  xgb_alpha: 6.920562038774711\n"
          ]
        }
      ],
      "source": [
        "best_trial = study.best_trial\n",
        "best_results = {\n",
        "    \"model_xgb\": best_trial.user_attrs[\"model_xgb\"],\n",
        "    \"model_dim\": best_trial.user_attrs[\"model_dim\"],\n",
        "    \"f1_discrepancy\": best_trial.user_attrs[\"f1_discrepancy\"],\n",
        "    \"val_f1\": best_trial.value,\n",
        "}\n",
        "best_hp = best_trial.user_attrs[\"hyperparameters\"]\n",
        "\n",
        "print(f\"Best model validation macro F1: {best_results['val_f1']:.4f}\")\n",
        "print(f\"F1 Score Discrepancy: {best_results['f1_discrepancy']:.4f}\")\n",
        "print(\"Parameters:\")\n",
        "for key, value in best_trial.params.items():\n",
        "    print(f\"  {key}: {value}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "be36c3e9",
      "metadata": {},
      "outputs": [],
      "source": [
        "trials_df = study.trials_dataframe()\n",
        "with open(os.path.join(LOG_DIR, \"trial_results.csv\"), \"w\") as f:\n",
        "    trials_df.to_csv(f, index=False)\n",
        "\n",
        "# TODO: Sample the best hyperparameters from the top N trials, in case theres multiple\n",
        "# possible peaks, or if the best trial is a freak anomaly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "e94a501e",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(os.path.join(LOG_DIR, \"best_hp.pkl\"), \"wb\") as f:\n",
        "    pickle.dump(best_hp, f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ada8d811",
      "metadata": {},
      "outputs": [],
      "source": [
        "with open(\"logs/optuna_exp_20250810_213811/best_hp.pkl\", \"rb\") as f:\n",
        "    loaded_best_hp = pickle.load(f)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ee060da2",
      "metadata": {
        "trusted": false
      },
      "source": [
        "## Inference with Optimized Model\n",
        "Using the best hyperparameters found by Optuna optimization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "957ba992",
      "metadata": {
        "trusted": false
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'best_results' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m pred_y = inference(\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m     test_X, model_xgb=\u001b[43mbest_results\u001b[49m[\u001b[33m\"\u001b[39m\u001b[33mmodel_xgb\u001b[39m\u001b[33m\"\u001b[39m], model_dim=best_results[\u001b[33m\"\u001b[39m\u001b[33mmodel_dim\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m      3\u001b[39m )\n",
            "\u001b[31mNameError\u001b[39m: name 'best_results' is not defined"
          ]
        }
      ],
      "source": [
        "pred_y = inference(\n",
        "    test_X, model_xgb=best_results[\"model_xgb\"], model_dim=best_results[\"model_dim\"]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d7bd3f0d",
      "metadata": {
        "trusted": false
      },
      "outputs": [],
      "source": [
        "pred_df = pd.DataFrame(\n",
        "    # zip(test_tfidf_df.index, np.where(pred_y > 0.5, 1, 0)), columns=[\"row ID\", \"label\"]\n",
        "    zip(test_tfidf_df.index, np.where(pred_y > 0.5, 1, 0)), columns=[\"id\", \"label\"]\n",
        ")\n",
        "# YYYYMMDD-HHMM-optuna.csv\n",
        "pred_df.to_csv(f\"{datetime.now().strftime('%Y%m%d-%H%M')}-optuna.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ba254dfe",
      "metadata": {},
      "source": [
        "## Stratified Cross-Validation with Model Ensembling\n",
        "Using the best hyperparameters found by Optuna, we'll now train multiple models using stratified cross-validation and ensemble their predictions for better performance and robustness."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "17c5e8cc",
      "metadata": {},
      "outputs": [],
      "source": [
        "def train_cv_ensemble(hp, X, y, test_X, n_splits=5, random_state=42):\n",
        "    \"\"\"\n",
        "    Train multiple models using stratified cross-validation and ensemble their predictions.\n",
        "    \n",
        "    Args:\n",
        "        hp: Hyperparameters object\n",
        "        X: Training features\n",
        "        y: Training labels\n",
        "        test_X: Test features for prediction\n",
        "        n_splits: Number of CV folds\n",
        "        random_state: Random state for reproducibility\n",
        "    \n",
        "    Returns:\n",
        "        dict: Contains ensemble predictions, individual model predictions, and CV scores\n",
        "    \"\"\"\n",
        "    # Set up stratified k-fold\n",
        "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=random_state)\n",
        "    \n",
        "    # Storage for models and predictions\n",
        "    cv_models = []\n",
        "    cv_scores = []\n",
        "    oof_predictions = np.zeros(len(X))  # Out-of-fold predictions\n",
        "    test_predictions = np.zeros((len(test_X), n_splits))  # Test predictions from each fold\n",
        "    \n",
        "    print(f\"Training {n_splits} models using stratified cross-validation...\")\n",
        "    \n",
        "    for fold, (train_idx, val_idx) in enumerate(skf.split(X, y)):\n",
        "        print(f\"Training fold {fold + 1}/{n_splits}\")\n",
        "        \n",
        "        # Split data for this fold\n",
        "        X_train_fold, X_val_fold = X[train_idx], X[val_idx]\n",
        "        y_train_fold, y_val_fold = y[train_idx], y[val_idx]\n",
        "        \n",
        "        # Train model for this fold\n",
        "        results = train(\n",
        "            hp, \n",
        "            train_X=X_train_fold, \n",
        "            train_y=y_train_fold, \n",
        "            val_X=X_val_fold, \n",
        "            val_y=y_val_fold, \n",
        "            quiet=True\n",
        "        )\n",
        "        \n",
        "        # Store model and validation score\n",
        "        cv_models.append({\n",
        "            'model_xgb': results['model_xgb'],\n",
        "            'model_dim': results['model_dim']\n",
        "        })\n",
        "        cv_scores.append(results['val_f1'])\n",
        "        \n",
        "        # Generate out-of-fold predictions\n",
        "        val_pred = inference(\n",
        "            X_val_fold, \n",
        "            model_xgb=results['model_xgb'], \n",
        "            model_dim=results['model_dim']\n",
        "        )\n",
        "        oof_predictions[val_idx] = val_pred\n",
        "        \n",
        "        # Generate test predictions for this fold\n",
        "        test_pred = inference(\n",
        "            test_X, \n",
        "            model_xgb=results['model_xgb'], \n",
        "            model_dim=results['model_dim']\n",
        "        )\n",
        "        test_predictions[:, fold] = test_pred\n",
        "        \n",
        "        print(f\"Fold {fold + 1} validation F1: {results['val_f1']:.4f}\")\n",
        "    \n",
        "    # Calculate overall CV score\n",
        "    oof_f1 = f1_score(y, (oof_predictions > 0.5).astype(int), average='macro')\n",
        "    \n",
        "    # Ensemble test predictions (simple averaging)\n",
        "    ensemble_test_pred = np.mean(test_predictions, axis=1)\n",
        "    \n",
        "    print(f\"\\nCross-validation results:\")\n",
        "    print(f\"Individual fold F1 scores: {[f'{score:.4f}' for score in cv_scores]}\")\n",
        "    print(f\"Mean CV F1: {np.mean(cv_scores):.4f}  {np.std(cv_scores):.4f}\")\n",
        "    print(f\"Out-of-fold F1: {oof_f1:.4f}\")\n",
        "    \n",
        "    return {\n",
        "        'cv_models': cv_models,\n",
        "        'cv_scores': cv_scores,\n",
        "        'mean_cv_score': np.mean(cv_scores),\n",
        "        'std_cv_score': np.std(cv_scores),\n",
        "        'oof_predictions': oof_predictions,\n",
        "        'oof_f1': oof_f1,\n",
        "        'test_predictions': test_predictions,\n",
        "        'ensemble_test_pred': ensemble_test_pred\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "3d8fe4c3",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training ensemble with optimal hyperparameters:\n",
            "Full training set size: 17184\n",
            "Test set size: 4296\n",
            "Training 3 models using stratified cross-validation...\n",
            "Training fold 1/3\n",
            "Fold 1 validation F1: 0.7226\n",
            "Training fold 2/3\n",
            "Fold 1 validation F1: 0.7226\n",
            "Training fold 2/3\n",
            "Fold 2 validation F1: 0.7227\n",
            "Training fold 3/3\n",
            "Fold 2 validation F1: 0.7227\n",
            "Training fold 3/3\n",
            "Fold 3 validation F1: 0.7269\n",
            "\n",
            "Cross-validation results:\n",
            "Individual fold F1 scores: ['0.7226', '0.7227', '0.7269']\n",
            "Mean CV F1: 0.7241  0.0020\n",
            "Out-of-fold F1: 0.7241\n",
            "Fold 3 validation F1: 0.7269\n",
            "\n",
            "Cross-validation results:\n",
            "Individual fold F1 scores: ['0.7226', '0.7227', '0.7269']\n",
            "Mean CV F1: 0.7241  0.0020\n",
            "Out-of-fold F1: 0.7241\n"
          ]
        }
      ],
      "source": [
        "# Combine train and validation sets for cross-validation\n",
        "full_train_X = np.vstack([train_X, val_X])\n",
        "full_train_y = np.hstack([train_y, val_y])\n",
        "\n",
        "print(f\"Training ensemble with optimal hyperparameters:\")\n",
        "print(f\"Full training set size: {len(full_train_X)}\")\n",
        "print(f\"Test set size: {len(test_X)}\")\n",
        "\n",
        "# Train ensemble using cross-validation\n",
        "ensemble_results = train_cv_ensemble(\n",
        "    hp=loaded_best_hp,\n",
        "    X=full_train_X,\n",
        "    y=full_train_y,\n",
        "    test_X=test_X,\n",
        "    n_splits=3,\n",
        "    random_state=HP.seed,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2f9fc687",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize ensemble results\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# 1. Cross-validation scores\n",
        "axes[0, 0].bar(range(1, len(ensemble_results['cv_scores']) + 1), ensemble_results['cv_scores'])\n",
        "axes[0, 0].axhline(y=ensemble_results['mean_cv_score'], color='r', linestyle='--', \n",
        "                   label=f\"Mean: {ensemble_results['mean_cv_score']:.4f}\")\n",
        "axes[0, 0].axhline(y=ensemble_results['oof_f1'], color='g', linestyle='--', \n",
        "                   label=f\"OOF: {ensemble_results['oof_f1']:.4f}\")\n",
        "axes[0, 0].set_xlabel('Fold')\n",
        "axes[0, 0].set_ylabel('F1 Score')\n",
        "axes[0, 0].set_title('Cross-Validation F1 Scores')\n",
        "axes[0, 0].legend()\n",
        "axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Prediction distribution for each fold\n",
        "test_preds = ensemble_results['test_predictions']\n",
        "for i in range(test_preds.shape[1]):\n",
        "    axes[0, 1].hist(test_preds[:, i], alpha=0.6, bins=30, label=f'Fold {i+1}')\n",
        "axes[0, 1].hist(ensemble_results['ensemble_test_pred'], alpha=0.8, bins=30, \n",
        "                color='black', label='Ensemble', linewidth=2)\n",
        "axes[0, 1].set_xlabel('Prediction Probability')\n",
        "axes[0, 1].set_ylabel('Count')\n",
        "axes[0, 1].set_title('Test Prediction Distributions')\n",
        "axes[0, 1].legend()\n",
        "\n",
        "# 3. Ensemble vs individual predictions scatter\n",
        "ensemble_pred = ensemble_results['ensemble_test_pred']\n",
        "individual_pred = test_preds[:, 0]  # First fold as example\n",
        "axes[1, 0].scatter(individual_pred, ensemble_pred, alpha=0.6)\n",
        "axes[1, 0].plot([0, 1], [0, 1], 'r--', label='y=x')\n",
        "axes[1, 0].set_xlabel('Individual Model Prediction (Fold 1)')\n",
        "axes[1, 0].set_ylabel('Ensemble Prediction')\n",
        "axes[1, 0].set_title('Ensemble vs Individual Predictions')\n",
        "axes[1, 0].legend()\n",
        "axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "# 4. Prediction variance across folds\n",
        "prediction_std = np.std(test_preds, axis=1)\n",
        "axes[1, 1].hist(prediction_std, bins=30, alpha=0.7)\n",
        "axes[1, 1].set_xlabel('Standard Deviation of Predictions')\n",
        "axes[1, 1].set_ylabel('Count')\n",
        "axes[1, 1].set_title('Prediction Uncertainty Across Folds')\n",
        "axes[1, 1].axvline(x=np.mean(prediction_std), color='r', linestyle='--', \n",
        "                   label=f'Mean: {np.mean(prediction_std):.4f}')\n",
        "axes[1, 1].legend()\n",
        "axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed statistics\n",
        "print(f\"\\nEnsemble Performance Summary:\")\n",
        "print(f\"============================\")\n",
        "print(f\"Single model validation F1 (best trial): {best_results['val_f1']:.4f}\")\n",
        "print(f\"Ensemble mean CV F1: {ensemble_results['mean_cv_score']:.4f}  {ensemble_results['std_cv_score']:.4f}\")\n",
        "print(f\"Ensemble out-of-fold F1: {ensemble_results['oof_f1']:.4f}\")\n",
        "print(f\"\")\n",
        "print(f\"Prediction Statistics:\")\n",
        "print(f\"Mean prediction uncertainty (std): {np.mean(prediction_std):.4f}\")\n",
        "print(f\"Max prediction uncertainty: {np.max(prediction_std):.4f}\")\n",
        "print(f\"Min prediction uncertainty: {np.min(prediction_std):.4f}\")\n",
        "\n",
        "# Compare single model vs ensemble predictions\n",
        "single_model_pred = inference(test_X, model_xgb=best_results[\"model_xgb\"], model_dim=best_results[\"model_dim\"])\n",
        "ensemble_pred = ensemble_results['ensemble_test_pred']\n",
        "\n",
        "print(f\"\\nPrediction Comparison:\")\n",
        "print(f\"Single model mean prediction: {np.mean(single_model_pred):.4f}\")\n",
        "print(f\"Ensemble mean prediction: {np.mean(ensemble_pred):.4f}\")\n",
        "print(f\"Correlation between single and ensemble: {np.corrcoef(single_model_pred, ensemble_pred)[0,1]:.4f}\")\n",
        "\n",
        "# Count prediction differences\n",
        "binary_single = (single_model_pred > 0.5).astype(int)\n",
        "binary_ensemble = (ensemble_pred > 0.5).astype(int)\n",
        "diff_count = np.sum(binary_single != binary_ensemble)\n",
        "print(f\"Number of different binary predictions: {diff_count} out of {len(binary_single)} ({diff_count/len(binary_single)*100:.2f}%)\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "ff532a64",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ensemble predictions saved to: 20250810-2311-ensemble-cv.csv\n",
            "Ensemble metadata saved to: ./logs/optuna_exp_20250810_225430/ensemble_metadata.json\n",
            "\n",
            "Final Ensemble Summary:\n",
            "======================\n",
            "Submission file: 20250810-2311-ensemble-cv.csv\n",
            "Ensemble CV F1: 0.7202  0.0045\n",
            "Out-of-fold F1: 0.7202\n",
            "Number of models: 2\n",
            "Prediction uncertainty (mean std): 0.0516\n"
          ]
        }
      ],
      "source": [
        "# Save ensemble predictions\n",
        "ensemble_pred_df = pd.DataFrame({\n",
        "    'id': test_tfidf_df.index,\n",
        "    'label': np.where(ensemble_results['ensemble_test_pred'] > 0.5, 1, 0)\n",
        "})\n",
        "\n",
        "# Save with ensemble identifier\n",
        "ensemble_filename = f\"{datetime.now().strftime('%Y%m%d-%H%M')}-ensemble-cv.csv\"\n",
        "ensemble_pred_df.to_csv(ensemble_filename, index=False)\n",
        "print(f\"Ensemble predictions saved to: {ensemble_filename}\")\n",
        "\n",
        "# Save ensemble models and results\n",
        "ensemble_data = {\n",
        "    \"hyperparameters\": asdict(loaded_best_hp),\n",
        "    \"cv_results\": ensemble_results,\n",
        "    \"experiment_name\": EXPERIMENT_NAME,\n",
        "    \"ensemble_filename\": ensemble_filename,\n",
        "    \"ensemble_performance\": {\n",
        "        \"mean_cv_f1\": ensemble_results[\"mean_cv_score\"],\n",
        "        \"std_cv_f1\": ensemble_results[\"std_cv_score\"],\n",
        "        \"oof_f1\": ensemble_results[\"oof_f1\"],\n",
        "    },\n",
        "}\n",
        "\n",
        "# Save ensemble metadata\n",
        "ensemble_metadata_file = os.path.join(LOG_DIR, \"ensemble_metadata.json\")\n",
        "with open(ensemble_metadata_file, \"w\") as f:\n",
        "    # Convert numpy types to native Python types for JSON serialization\n",
        "    def convert_numpy(obj):\n",
        "        if isinstance(obj, np.ndarray):\n",
        "            return obj.tolist()\n",
        "        elif isinstance(obj, np.float64):\n",
        "            return float(obj)\n",
        "        elif isinstance(obj, np.int64):\n",
        "            return int(obj)\n",
        "        return obj\n",
        "    \n",
        "    # Create a JSON-serializable version\n",
        "    json_data = {}\n",
        "    for key, value in ensemble_data.items():\n",
        "        if key == 'cv_results':\n",
        "            # Save only the essential metrics, not the models\n",
        "            json_data[key] = {\n",
        "                'cv_scores': [float(x) for x in value['cv_scores']],\n",
        "                'mean_cv_score': float(value['mean_cv_score']),\n",
        "                'std_cv_score': float(value['std_cv_score']),\n",
        "                'oof_f1': float(value['oof_f1'])\n",
        "            }\n",
        "        else:\n",
        "            json_data[key] = value\n",
        "    \n",
        "    json.dump(json_data, f, indent=2)\n",
        "\n",
        "print(f\"Ensemble metadata saved to: {ensemble_metadata_file}\")\n",
        "\n",
        "# Optionally save individual models (warning: large file size)\n",
        "save_models = False  # Set to True if you want to save all models\n",
        "if save_models:\n",
        "    models_file = os.path.join(LOG_DIR, \"ensemble_models.pkl\")\n",
        "    with open(models_file, \"wb\") as f:\n",
        "        pickle.dump(ensemble_results['cv_models'], f)\n",
        "    print(f\"Ensemble models saved to: {models_file}\")\n",
        "\n",
        "print(f\"\\nFinal Ensemble Summary:\")\n",
        "print(f\"======================\")\n",
        "print(f\"Submission file: {ensemble_filename}\")\n",
        "print(f\"Ensemble CV F1: {ensemble_results['mean_cv_score']:.4f}  {ensemble_results['std_cv_score']:.4f}\")\n",
        "print(f\"Out-of-fold F1: {ensemble_results['oof_f1']:.4f}\")\n",
        "print(f\"Number of models: {len(ensemble_results['cv_models'])}\")\n",
        "print(f\"Prediction uncertainty (mean std): {np.mean(np.std(ensemble_results['test_predictions'], axis=1)):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1fada723",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Run the LogisticRegression + Optuna hyperparameter optimization\n",
        "# This will be more efficient than XGBoost and optimize the entire pipeline\n",
        "\n",
        "# Note: Uncomment the line below to run the optimization\n",
        "# %run task3/logistic_optuna.py\n",
        "\n",
        "print(\"LogisticRegression + Optuna optimization script created!\")\n",
        "print(\"The script optimizes:\")\n",
        "print(\"  1. TfidfVectorizer hyperparameters (max_features, min_df, max_df, ngram_range, etc.)\")\n",
        "print(\"  2. SelectKBest feature selection (k value)\")\n",
        "print(\"  3. LogisticRegression hyperparameters (C, penalty, solver, etc.)\")\n",
        "print()\n",
        "print(\"Key optimizations:\")\n",
        "print(\"  - Text cleaning is done once to save time\")\n",
        "print(\"  - Uses 5-fold stratified cross-validation\")\n",
        "print(\"  - Optimizes for macro F1 score\")\n",
        "print(\"  - Handles solver/penalty compatibility automatically\")\n",
        "print(\"  - Saves all results, models, and submission files\")\n",
        "print()\n",
        "print(\"To run: uncomment the %run line above or execute 'python task3/logistic_optuna.py' in terminal\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "50-007-ml-project",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
