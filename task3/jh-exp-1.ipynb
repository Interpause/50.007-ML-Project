{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2304c4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "### REMOVE LATER ###\n",
    "# Go up one directory since notebook inside task3/ folder.\n",
    "import os\n",
    "try:\n",
    "    if UP_DIR:\n",
    "        print(\"skipping\")\n",
    "except NameError:\n",
    "    os.chdir(\"..\")\n",
    "    UP_DIR = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ad56939",
   "metadata": {},
   "source": [
    "# JH's Task 3 Experiment 1\n",
    "(NOTE: keep this H1 header block or add it later to denote the boundaries between notebooks when we combined later)\n",
    "\n",
    "I don't know what I am doing yet for this."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be8e8fa9",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c26973c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d84100",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41f9b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Hparams:\n",
    "    val_split: float = 0.2\n",
    "    seed: int = 42\n",
    "    \n",
    "    pca_n_components = 400\n",
    "    \n",
    "\n",
    "HP = Hparams()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15db208",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_CSV = \"./data/train.csv\"\n",
    "TRAIN_TFIDF_CSV = \"./data/train_tfidf_features.csv\"\n",
    "TEST_CSV = \"./data/test.csv\"\n",
    "TEST_TFIDF_CSV = \"./data/test_tfidf_features.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e36c357",
   "metadata": {},
   "source": [
    "## Data Engineering\n",
    "Instead of using the tfidf features given in the comp, we can engineer our own tfidf features with better filtering logic, or using something other than tfidf altogether to arrive at vector representations, or perhaps even use a strategy that use non-vector representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "361d387f",
   "metadata": {},
   "source": [
    "### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e58864",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_CSV, index_col=\"id\")\n",
    "train_tfidf_df = pd.read_csv(TRAIN_TFIDF_CSV, index_col=\"id\")\n",
    "test_df = pd.read_csv(TEST_CSV, index_col=\"id\")\n",
    "test_tfidf_df = pd.read_csv(TEST_TFIDF_CSV, index_col=\"id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff533efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_to_np(df: pd.DataFrame):\n",
    "    \"\"\"Convert the tfidf CSVs to X array of features and y array of labels, ordered\n",
    "    by id.\n",
    "    \"\"\"\n",
    "    df = df.sort_index()\n",
    "\n",
    "    if \"label\" in df.columns:\n",
    "        y = df.pop(\"label\").to_numpy()\n",
    "    else:\n",
    "        y = None\n",
    "\n",
    "    X = df.to_numpy()\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8bd2b4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, val_X, train_y, val_y = train_test_split(*tfidf_to_np(train_tfidf_df), test_size=HP.val_split, random_state=HP.seed)\n",
    "test_X, test_y = tfidf_to_np(test_tfidf_df)\n",
    "\n",
    "print(\"Dataset splits:\")\n",
    "print(\"  train:\", len(train_X))\n",
    "print(\"  val:  \", len(val_X))\n",
    "print(\"  test: \", len(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab0bf131",
   "metadata": {},
   "source": [
    "### Fit PCA For Dim Reduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "428f5426",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca = PCA(n_components=HP.pca_n_components, random_state=HP.seed)\n",
    "\n",
    "model_pca.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b37b9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratios = list(zip(range(HP.pca_n_components), model_pca.explained_variance_ratio_))\n",
    "ratios.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "print(\"Most Informative Dimensions:\")\n",
    "for idx, val in ratios[:3]:\n",
    "    print(f\"  Dim {idx}: {val}\")\n",
    "\n",
    "print(\"Noise:\", model_pca.noise_variance_)\n",
    "print(\"Total Explained Variance:\", sum(model_pca.explained_variance_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4f2255",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_train_X = model_pca.transform(train_X)\n",
    "t_val_X = model_pca.transform(val_X)\n",
    "t_test_X = model_pca.transform(test_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee060da2",
   "metadata": {},
   "source": [
    "## Fit XGBoost\n",
    "Its boosted trees or random forests for both classification or regression.\n",
    "\n",
    "Tutorial: <https://xgboost.readthedocs.io/en/stable/python/python_intro.html#setting-parameters>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eccafd81",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtrain = xgb.DMatrix(t_train_X, label=train_y)\n",
    "dval = xgb.DMatrix(t_val_X, label=val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba769db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://xgboost.readthedocs.io/en/stable/tutorials/param_tuning.html\n",
    "params = {\n",
    "    \"validate_parameters\": True,\n",
    "    \n",
    "    \"colsample_bynode\": 0.8,\n",
    "    \"learning_rate\": 0.25,\n",
    "    \"max_depth\": 4,\n",
    "    \"num_parallel_tree\": 500,\n",
    "    # TODO: when you use hinge loss cuz its easier to understand but actually logistic\n",
    "    # regression converges faster, but actually you should just add another eval metric\n",
    "    # \"objective\": \"binary:hinge\",\n",
    "    \"objective\": \"binary:logistic\",\n",
    "    \"subsample\": 0.6,\n",
    "    \"tree_method\": \"hist\",\n",
    "    \"device\": \"gpu\",\n",
    "}\n",
    "num_round = 200\n",
    "early_stopping_rounds = 10\n",
    "# Last set is used by xgb's early stopping.\n",
    "eval_list = [(dtrain, \"train\"), (dval, \"val\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46aeae03",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "bst = xgb.train(\n",
    "    params,\n",
    "    dtrain,\n",
    "    num_round,\n",
    "    evals=eval_list,\n",
    "    evals_result=results,\n",
    "    early_stopping_rounds=early_stopping_rounds,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da6b7dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#xgb.plot_importance(bst)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3df062b",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02cae4d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtest = xgb.DMatrix(t_test_X)\n",
    "\n",
    "pred_y = bst.predict(dtest, iteration_range=(0, bst.best_iteration+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bd3f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame(\n",
    "    zip(test_tfidf_df.index, np.where(pred_y > 0.5, 1, 0)), columns=[\"id\", \"label\"]\n",
    ")\n",
    "pred_df.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b0d244",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "50-007-ml-project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
