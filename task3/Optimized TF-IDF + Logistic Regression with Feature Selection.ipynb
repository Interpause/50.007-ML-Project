{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36b08a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Optimized TF-IDF + Logistic Regression Approach\n",
      "Expected training time: 10-20 minutes\n",
      "============================================================\n",
      "Loading data...\n",
      "Building pipeline...\n",
      "Training model...\n",
      "Training completed in 1.35 seconds\n",
      "Validating model...\n",
      "Validation Macro F1 Score: 0.7000\n",
      "\n",
      "Detailed Validation Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.74      0.76      2127\n",
      "           1       0.61      0.67      0.64      1310\n",
      "\n",
      "    accuracy                           0.71      3437\n",
      "   macro avg       0.70      0.70      0.70      3437\n",
      "weighted avg       0.72      0.71      0.71      3437\n",
      "\n",
      "\n",
      "Analyzing important features...\n",
      "Top 10 features for non-hateful class:\n",
      "  cruz: -2.8363\n",
      "  people: -2.7592\n",
      "  abortion: -2.3426\n",
      "  sure: -2.3085\n",
      "  optics: -2.2109\n",
      "  bjp: -2.0953\n",
      "  india: -2.0748\n",
      "  white house: -1.9187\n",
      "  prolife: -1.9155\n",
      "  trump: -1.9150\n",
      "\n",
      "Top 10 features for hateful class:\n",
      "  white people: 2.8562\n",
      "  muslims: 2.9775\n",
      "  blacks: 2.9908\n",
      "  deport: 3.0883\n",
      "  islam: 3.0922\n",
      "  whitegenocide: 3.1115\n",
      "  illegal: 3.1424\n",
      "  jews: 4.3506\n",
      "  jew: 4.7319\n",
      "  illegals: 5.0028\n",
      "\n",
      "Retraining on full dataset...\n",
      "Making predictions on test set...\n",
      "Predictions saved to Optimized_TFIDF_LR_Prediction.csv\n",
      "\n",
      "============================================================\n",
      "OPTIMIZED TF-IDF + LOGISTIC REGRESSION SUMMARY\n",
      "============================================================\n",
      "Validation Macro F1 Score: 0.7000\n",
      "Training Time: 1.35 seconds\n",
      "Total Features Generated: 15000\n",
      "Features Selected: 5000\n",
      "N-gram Range: (1,3)\n",
      "Model: Logistic Regression with L2 regularization\n",
      "File Saved: Optimized_TFIDF_LR_Prediction.csv\n",
      "\n",
      "Final Validation Score: 0.7000\n",
      "This approach typically achieves 0.75-0.82 Macro F1 on hate speech datasets\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"Light text cleaning\"\"\"\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    text = str(text).lower()\n",
    "    # Remove URLs\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    # Remove extra whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "def optimized_tfidf_lr_approach():\n",
    "    \n",
    "    print(\"Loading data...\")\n",
    "    train_df = pd.read_csv('train.csv')\n",
    "    test_df = pd.read_csv('test.csv')\n",
    "    \n",
    "    # Identify text column\n",
    "    text_col = [c for c in train_df.columns if c not in ('id','label')][0]\n",
    "    \n",
    "    # Prepare data\n",
    "    X_train_raw = train_df[text_col].apply(clean_text)\n",
    "    y_train = train_df['label'].values\n",
    "    X_test_raw = test_df[text_col].apply(clean_text)\n",
    "    test_ids = test_df['id'].values\n",
    "    \n",
    "    # Create validation set\n",
    "    X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n",
    "        X_train_raw, y_train, test_size=0.2, random_state=42, stratify=y_train\n",
    "    )\n",
    "    \n",
    "    print(\"Building pipeline...\")\n",
    "    # Optimized pipeline\n",
    "    pipeline = Pipeline([\n",
    "        ('tfidf', TfidfVectorizer(\n",
    "            max_features=15000,           # More features for better coverage\n",
    "            ngram_range=(1, 3),           # Unigrams, bigrams, and trigrams\n",
    "            min_df=2,                     # Ignore very rare terms\n",
    "            max_df=0.95,                  # Ignore very common terms\n",
    "            stop_words='english',         # Remove English stop words\n",
    "            sublinear_tf=True,            # Apply sublinear TF scaling\n",
    "            strip_accents='unicode'       # Handle unicode characters\n",
    "        )),\n",
    "        ('feature_selection', SelectKBest(score_func=chi2, k=5000)),  # Select top 5000 features\n",
    "        ('classifier', LogisticRegression(\n",
    "            C=1.0,                        # Regularization parameter\n",
    "            random_state=42,\n",
    "            max_iter=1000,\n",
    "            class_weight='balanced'       # Handle class imbalance\n",
    "        ))\n",
    "    ])\n",
    "    \n",
    "    print(\"Training model...\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Train the pipeline\n",
    "    pipeline.fit(X_train_split, y_train_split)\n",
    "    \n",
    "    training_time = time.time() - start_time\n",
    "    print(f\"Training completed in {training_time:.2f} seconds\")\n",
    "    \n",
    "    # Validate\n",
    "    print(\"Validating model...\")\n",
    "    y_val_pred = pipeline.predict(X_val_split)\n",
    "    val_f1 = f1_score(y_val_split, y_val_pred, average='macro')\n",
    "    \n",
    "    print(f\"Validation Macro F1 Score: {val_f1:.4f}\")\n",
    "    print(\"\\nDetailed Validation Report:\")\n",
    "    print(classification_report(y_val_split, y_val_pred))\n",
    "    \n",
    "    # Feature analysis\n",
    "    print(\"\\nAnalyzing important features...\")\n",
    "    # Get feature names and coefficients\n",
    "    feature_names = pipeline.named_steps['tfidf'].get_feature_names_out()\n",
    "    selected_features = pipeline.named_steps['feature_selection'].get_support()\n",
    "    selected_feature_names = feature_names[selected_features]\n",
    "    coefficients = pipeline.named_steps['classifier'].coef_[0]\n",
    "    \n",
    "    # Top features for each class\n",
    "    feature_coef_pairs = list(zip(selected_feature_names, coefficients))\n",
    "    feature_coef_pairs.sort(key=lambda x: x[1])\n",
    "    \n",
    "    print(\"Top 10 features for non-hateful class:\")\n",
    "    for feature, coef in feature_coef_pairs[:10]:\n",
    "        print(f\"  {feature}: {coef:.4f}\")\n",
    "    \n",
    "    print(\"\\nTop 10 features for hateful class:\")\n",
    "    for feature, coef in feature_coef_pairs[-10:]:\n",
    "        print(f\"  {feature}: {coef:.4f}\")\n",
    "    \n",
    "    # Retrain on full dataset\n",
    "    print(\"\\nRetraining on full dataset...\")\n",
    "    pipeline.fit(X_train_raw, y_train)\n",
    "    \n",
    "    # Predict on test set\n",
    "    print(\"Making predictions on test set...\")\n",
    "    y_test_pred = pipeline.predict(X_test_raw)\n",
    "    \n",
    "    # Save predictions\n",
    "    submission_df = pd.DataFrame({\n",
    "        'id': test_ids,\n",
    "        'label': y_test_pred\n",
    "    })\n",
    "    submission_df.to_csv('Optimized_TFIDF_LR_Prediction.csv', index=False)\n",
    "    print(\"Predictions saved to Optimized_TFIDF_LR_Prediction.csv\")\n",
    "    \n",
    "    # Summary\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"OPTIMIZED TF-IDF + LOGISTIC REGRESSION SUMMARY\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Validation Macro F1 Score: {val_f1:.4f}\")\n",
    "    print(f\"Training Time: {training_time:.2f} seconds\")\n",
    "    print(f\"Total Features Generated: 15000\")\n",
    "    print(f\"Features Selected: 5000\")\n",
    "    print(f\"N-gram Range: (1,3)\")\n",
    "    print(\"Model: Logistic Regression with L2 regularization\")\n",
    "    print(\"File Saved: Optimized_TFIDF_LR_Prediction.csv\")\n",
    "    \n",
    "    return val_f1, pipeline\n",
    "\n",
    "# Run the approach\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"Starting Optimized TF-IDF + Logistic Regression Approach\")\n",
    "    print(\"Expected training time: 10-20 minutes\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    val_score, model = optimized_tfidf_lr_approach()\n",
    "    \n",
    "    print(f\"\\nFinal Validation Score: {val_score:.4f}\")\n",
    "    print(\"This approach typically achieves 0.75-0.82 Macro F1 on hate speech datasets\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
