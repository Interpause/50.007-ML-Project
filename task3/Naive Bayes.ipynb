{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db799999",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vectorizing text data...\n",
      "Training set shape: (17184, 10000)\n",
      "Test set shape: (4296, 10000)\n",
      "Training Naive Bayes model...\n",
      "Evaluating on validation set...\n",
      "\n",
      "==================================================\n",
      "NAIVE BAYES EVALUATION RESULTS\n",
      "==================================================\n",
      "Macro F1 Score: 0.6868\n",
      "\n",
      "Per-Class F1 Scores:\n",
      "  Class 0: 0.7867\n",
      "  Class 1: 0.5869\n",
      "\n",
      "Detailed Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.84      0.79      2127\n",
      "           1       0.67      0.52      0.59      1310\n",
      "\n",
      "    accuracy                           0.72      3437\n",
      "   macro avg       0.70      0.68      0.69      3437\n",
      "weighted avg       0.71      0.72      0.71      3437\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[1783  344]\n",
      " [ 623  687]]\n",
      "\n",
      "Manual Macro F1 Verification:\n",
      "Manual Macro F1: 0.6868\n",
      "Sklearn Macro F1: 0.6868\n",
      "\n",
      "Retraining on full dataset...\n",
      "Making final predictions on test set...\n",
      "Predictions saved to NaiveBayes_Prediction.csv\n",
      "\n",
      "Top Features Analysis:\n",
      "\n",
      "Top 15 features for non-hateful class:\n",
      "  1. the: -4.6158\n",
      "  2. white: -4.6259\n",
      "  3. to: -4.9181\n",
      "  4. is: -5.0322\n",
      "  5. of: -5.0358\n",
      "  6. and: -5.1714\n",
      "  7. you: -5.1819\n",
      "  8. in: -5.2319\n",
      "  9. people: -5.3102\n",
      "  10. are: -5.3292\n",
      "  11. for: -5.4891\n",
      "  12. on: -5.6206\n",
      "  13. racist: -5.6529\n",
      "  14. not: -5.6856\n",
      "  15. that: -5.7056\n",
      "\n",
      "Top 15 features for hateful class:\n",
      "  1. white: -4.5596\n",
      "  2. the: -4.6604\n",
      "  3. to: -4.8969\n",
      "  4. and: -5.0902\n",
      "  5. is: -5.1467\n",
      "  6. of: -5.1544\n",
      "  7. you: -5.2549\n",
      "  8. are: -5.2567\n",
      "  9. in: -5.3832\n",
      "  10. people: -5.4523\n",
      "  11. for: -5.4960\n",
      "  12. they: -5.5760\n",
      "  13. black: -5.6744\n",
      "  14. that: -5.7866\n",
      "  15. all: -5.7997\n",
      "\n",
      "Naive Bayes Training Complete!\n",
      "Final Macro F1 Score on Validation Set: 0.6868\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load your data (adjust file paths as needed)\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "# Identify text column\n",
    "text_col = [c for c in train_df.columns if c not in ('id','label')][0]\n",
    "X_text = train_df[text_col].astype(str).tolist()\n",
    "y = train_df['label'].values\n",
    "X_test_txt = test_df[text_col].astype(str).tolist()\n",
    "test_ids = test_df['id'].values\n",
    "\n",
    "# Preprocess text\n",
    "def clean(text):\n",
    "    t = text.lower()\n",
    "    t = re.sub(r'http\\S+|www\\S+', '', t)\n",
    "    t = re.sub(r'@\\w+|#\\w+', '', t)\n",
    "    return re.sub(r'\\s+', ' ', t).strip()\n",
    "\n",
    "X_text = [clean(t) for t in X_text]\n",
    "X_test_txt = [clean(t) for t in X_test_txt]\n",
    "\n",
    "# TF-IDF Vectorization\n",
    "print(\"Vectorizing text data...\")\n",
    "tfidf = TfidfVectorizer(\n",
    "    max_features=10000,\n",
    "    ngram_range=(1, 2),\n",
    "    min_df=3,\n",
    "    strip_accents='unicode'\n",
    ")\n",
    "\n",
    "X_tfidf = tfidf.fit_transform(X_text)\n",
    "X_test_tfidf = tfidf.transform(X_test_txt)\n",
    "\n",
    "print(f\"Training set shape: {X_tfidf.shape}\")\n",
    "print(f\"Test set shape: {X_test_tfidf.shape}\")\n",
    "\n",
    "# Split for validation\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_tfidf, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Train Naive Bayes Model\n",
    "print(\"Training Naive Bayes model...\")\n",
    "nb_model = MultinomialNB(alpha=0.1)\n",
    "nb_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on validation set\n",
    "print(\"Evaluating on validation set...\")\n",
    "y_val_pred = nb_model.predict(X_val)\n",
    "y_val_proba = nb_model.predict_proba(X_val)\n",
    "\n",
    "# EVALUATION CODE STARTS HERE\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"NAIVE BAYES EVALUATION RESULTS\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Calculate Macro F1 Score\n",
    "macro_f1 = f1_score(y_val, y_val_pred, average='macro')\n",
    "print(f\"Macro F1 Score: {macro_f1:.4f}\")\n",
    "\n",
    "# Calculate per-class F1 scores\n",
    "classes = np.unique(y_val)\n",
    "print(f\"\\nPer-Class F1 Scores:\")\n",
    "for class_label in classes:\n",
    "    tp = np.sum((y_val == class_label) & (y_val_pred == class_label))\n",
    "    fp = np.sum((y_val != class_label) & (y_val_pred == class_label))\n",
    "    fn = np.sum((y_val == class_label) & (y_val_pred != class_label))\n",
    "    \n",
    "    if tp + fp + fn > 0:\n",
    "        f1_class = tp / (tp + 0.5 * (fp + fn))\n",
    "        print(f\"  Class {class_label}: {f1_class:.4f}\")\n",
    "    else:\n",
    "        print(f\"  Class {class_label}: 0.0000\")\n",
    "\n",
    "# Detailed classification report\n",
    "print(f\"\\nDetailed Classification Report:\")\n",
    "print(classification_report(y_val, y_val_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "print(f\"\\nConfusion Matrix:\")\n",
    "cm = confusion_matrix(y_val, y_val_pred)\n",
    "print(cm)\n",
    "\n",
    "# Manual Macro F1 calculation for verification\n",
    "print(f\"\\nManual Macro F1 Verification:\")\n",
    "f1_scores = []\n",
    "for class_label in classes:\n",
    "    tp = np.sum((y_val == class_label) & (y_val_pred == class_label))\n",
    "    fp = np.sum((y_val != class_label) & (y_val_pred == class_label))\n",
    "    fn = np.sum((y_val == class_label) & (y_val_pred != class_label))\n",
    "    \n",
    "    if tp + fp + fn > 0:\n",
    "        f1_class = tp / (tp + 0.5 * (fp + fn))\n",
    "        f1_scores.append(f1_class)\n",
    "    else:\n",
    "        f1_scores.append(0.0)\n",
    "\n",
    "manual_macro_f1 = np.mean(f1_scores)\n",
    "print(f\"Manual Macro F1: {manual_macro_f1:.4f}\")\n",
    "print(f\"Sklearn Macro F1: {macro_f1:.4f}\")\n",
    "\n",
    "# Retrain on full dataset and make final predictions\n",
    "print(f\"\\nRetraining on full dataset...\")\n",
    "nb_model_full = MultinomialNB(alpha=0.1)\n",
    "nb_model_full.fit(X_tfidf, y)\n",
    "\n",
    "# Make final predictions on test set\n",
    "print(\"Making final predictions on test set...\")\n",
    "y_test_pred = nb_model_full.predict(X_test_tfidf)\n",
    "\n",
    "# Save predictions\n",
    "submission_df = pd.DataFrame({\n",
    "    'id': test_ids,\n",
    "    'label': y_test_pred\n",
    "})\n",
    "\n",
    "submission_df.to_csv('NaiveBayes_Prediction.csv', index=False)\n",
    "print(\"Predictions saved to NaiveBayes_Prediction.csv\")\n",
    "\n",
    "# Feature analysis\n",
    "print(f\"\\nTop Features Analysis:\")\n",
    "feature_names = tfidf.get_feature_names_out()\n",
    "feature_log_prob = nb_model_full.feature_log_prob_\n",
    "\n",
    "# Get top features for each class\n",
    "if len(nb_model_full.classes_) == 2:\n",
    "    # Class 0 (non-hateful)\n",
    "    top_features_0 = np.argsort(feature_log_prob[0])[-15:][::-1]\n",
    "    print(f\"\\nTop 15 features for non-hateful class:\")\n",
    "    for i, idx in enumerate(top_features_0):\n",
    "        print(f\"  {i+1}. {feature_names[idx]}: {feature_log_prob[0][idx]:.4f}\")\n",
    "    \n",
    "    # Class 1 (hateful)\n",
    "    top_features_1 = np.argsort(feature_log_prob[1])[-15:][::-1]\n",
    "    print(f\"\\nTop 15 features for hateful class:\")\n",
    "    for i, idx in enumerate(top_features_1):\n",
    "        print(f\"  {i+1}. {feature_names[idx]}: {feature_log_prob[1][idx]:.4f}\")\n",
    "\n",
    "print(f\"\\nNaive Bayes Training Complete!\")\n",
    "print(f\"Final Macro F1 Score on Validation Set: {macro_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
